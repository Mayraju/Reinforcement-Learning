{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "U3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NIAleJXwusJ",
        "outputId": "ee260471-2fa6-49b3-921c-fbe85ba1f600",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/Mayraju/datasets.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'datasets'...\n",
            "remote: Enumerating objects: 35, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (18/18), done.\u001b[K\n",
            "remote: Total 35 (delta 14), reused 35 (delta 14), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (35/35), done.\n",
            "Checking out files: 100% (24/24), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6CZMmN52cGZ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from keras import optimizers\n",
        "from keras import backend as K\n",
        "import json\n",
        "from sklearn.utils import shuffle\n",
        "import os\n",
        "import sys\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9jHElGH3A7Y"
      },
      "source": [
        "#Data class processing\n",
        "class data_cls:\n",
        "  def __init__(self,train_test,**kwargs):\n",
        "     col_names = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
        "            \"dst_bytes\",\"land_f\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
        "            \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
        "            \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
        "            \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
        "            \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
        "            \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
        "            \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
        "            \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
        "            \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"labels\",\"dificulty\"]\n",
        "     self.index = 0\n",
        "     self.loaded = False\n",
        "     self.train_test = train_test\n",
        "     self.train_path = kwargs.get('train_path','/content/datasets/datasets/NSL/KDDTrain+.txt')\n",
        "     self.test_path = kwargs.get('test_path','/content/datasets/datasets/NSL/KDDTest+.txt')\n",
        "     self.formated_train_path = kwargs.get('formated_train_path',\"/content/datasets/datasets/formated/formated_train_adv.data.txt\")\n",
        "     self.formated_test_path = kwargs.get('formated_test_path',\"/content/datasets/datasets/formated/formated_test_adv.data.txt\")\n",
        "     self.attack_types = ['normal','Dos','Probe','R2L','U2R']\n",
        "     self.attack_names = []\n",
        "     self.attack_map = {'normal':'normal',\n",
        "                        \n",
        "                        'back' :'Dos',\n",
        "                        'land' :'Dos',\n",
        "                        'neptune':'Dos',\n",
        "                        'pod':'Dos',\n",
        "                        'smurf':'Dos',\n",
        "                        'teardrop':'Dos',\n",
        "                        'mailbomb':'Dos',\n",
        "                        'apache2':'Dos',\n",
        "                        'processtable':'Dos',\n",
        "                         'udpstorm':'Dos',\n",
        "                        \n",
        "                        'ipsweep':'Probe',\n",
        "                        'nmap':'Probe',\n",
        "                        'portsweep':'Probe',\n",
        "                        'satan':'Probe',\n",
        "                        'mscan':'Probe',\n",
        "                        'saint':'Probe',\n",
        "                        \n",
        "                        'ftp_write':'R2L',\n",
        "                        'guess_passwd':'R2L',\n",
        "                        'imap':'R2L',\n",
        "                        'multihop':'R2L',\n",
        "                        'phf':'R2L',\n",
        "                        'spy':'R2L',\n",
        "                        'warezclient':'R2L',\n",
        "                        'warezmaster':'R2L',\n",
        "                        'sendmail':'R2L',\n",
        "                        'named':'R2L',\n",
        "                        'snmpgetattack':'R2L',\n",
        "                        'snmpguess':'R2L',\n",
        "                        'xlock':'R2L',\n",
        "                        'xsnoop':'R2L',\n",
        "                        'worm':'R2L',\n",
        "                        \n",
        "                        \n",
        "                        'buffer_overflow':'U2R',\n",
        "                        'loadmodule':'U2R',\n",
        "                        'perl':'U2R',\n",
        "                        'rootkit':'U2R',\n",
        "                        'httptunnel':'U2R',\n",
        "                        'ps':'U2R',\n",
        "                        'sqlattack':'U2R',\n",
        "                        'xterm':'U2R'\n",
        "                      }\n",
        "     self.all_attack_names = list(self.attack_map.keys())\n",
        "     formated = False\n",
        "     if os.path.exists(self.formated_train_path) and os.path.exists(self.formated_test_path):\n",
        "       formated = True\n",
        "     self.formated_dir = \"/content/datasets/datasets/formated\"\n",
        "     if not os.path.exists(self.formated_dir):\n",
        "       os.makedirs(self.formated_dir)\n",
        "    \n",
        "\n",
        "    # if it does not exist,it's needed to format the data\n",
        "\n",
        "     if not formated:\n",
        "        self.df = pd.read_csv(self.train_path,sep=',',names=col_names,index_col=False) #reading the train data\n",
        "        if 'dificulty' in self.df.columns:\n",
        "         self.df.drop('dificulty',axis=1,inplace=True)\n",
        "        data2 = pd.read_csv(self.test_path,sep=',',names=col_names,index_col=False) #reading the test data\n",
        "        if 'dificulty' in data2:\n",
        "           del(data2['dificulty'])\n",
        "        train_indx = self.df.shape[0]\n",
        "        frames = [self.df,data2]\n",
        "        self.df=pd.concat(frames)\n",
        "\n",
        "        #dataFrame processing\n",
        "        self.df = pd.concat([self.df.drop('protocol_type',axis=1),pd.get_dummies(self.df['protocol_type'])],axis=1)\n",
        "        self.df = pd.concat([self.df.drop('service',axis=1),pd.get_dummies(self.df['service'])],axis=1)\n",
        "        self.df = pd.concat([self.df.drop('flag',axis=1),pd.get_dummies(self.df['flag'])],axis=1)\n",
        "\n",
        "      # 1 if 'su root' command attempted; 0 otherwise\n",
        "        self.df['su_attempted'] = self.df['su_attempted'].replace(2.0,0.0)\n",
        "\n",
        "      #one hot encoding for labels\n",
        "        self.df = pd.concat([self.df.drop('labels',axis=1),pd.get_dummies(self.df['labels'])],axis=1)\n",
        "\n",
        "      #Normalization of the df\n",
        "\n",
        "      #normalizd_df =(df-df.mean())/df.std()\n",
        "\n",
        "        for indx,dtype in self.df.dtypes.iteritems():\n",
        "          if dtype == 'float64' or dtype == 'int64':\n",
        "            if self.df[indx].max() == 0 and self.df[indx].min() == 0:\n",
        "              self.df[indx] = 0\n",
        "            else:\n",
        "              self.df[indx] = (self.df[indx]-self.df[indx].min())/(self.df[indx].max()-self.df[indx].min())\n",
        "      \n",
        "\n",
        "      #save data\n",
        "        test_df = self.df.iloc[train_indx:self.df.shape[0]]\n",
        "        test_df =shuffle(test_df,random_state=np.random.randint(0,100))\n",
        "        self.df = self.df[:train_indx]\n",
        "        self.df = shuffle(self.df,random_state=np.random.randint(0,100))\n",
        "        test_df.to_csv(self.formated_test_path,sep=',',index=False)\n",
        "        self.df.to_csv(self.formated_train_path,sep=',',index=False)\n",
        "\n",
        "        for att in self.attack_map:\n",
        "          if att in self.df.columns:\n",
        "            if np.sum(self.df[att].values) > 1:\n",
        "               self.attack_names.append(att)\n",
        "\n",
        "\n",
        "  def get_shape(self):\n",
        "    if self.loaded is False:\n",
        "      self._load_df()\n",
        "    self.data_shape = self.df.shape\n",
        "    \n",
        "    return self.data_shape\n",
        "\n",
        "  def get_batch(self,batch_size=100):\n",
        "        if self.loaded is False:\n",
        "            self._load_df()\n",
        "        \n",
        "        # Read the df rows\n",
        "        indexes = list(range(self.index,self.index+batch_size))    \n",
        "        if max(indexes)>self.data_shape[0]-1:\n",
        "            dif = max(indexes)-self.data_shape[0]\n",
        "            indexes[len(indexes)-dif-1:len(indexes)] = list(range(dif+1))\n",
        "            self.index=batch_size-dif\n",
        "            batch = self.df.iloc[indexes]\n",
        "        else: \n",
        "            batch = self.df.iloc[indexes]\n",
        "            self.index += batch_size    \n",
        "            \n",
        "        labels = batch[self.attack_names]\n",
        "        print(\"labels\")\n",
        "        print(self.all_attack_names)\n",
        "        batch = batch.drop(self.all_attack_names,axis=1)\n",
        "        print(\"batch\")\n",
        "        return batch,labels\n",
        "\n",
        "  def get_full(self):\n",
        "        if self.loaded is False:\n",
        "           self._load_df()\n",
        "\n",
        "        labels = self.df[self.attack_names]\n",
        "        batch = self.df.drop(self.all_attack_names,axis=1)\n",
        "        return batch,labels\n",
        "\n",
        "   # one random sample ni generate chestunam and ani attack types > 1 ni store chestunam\n",
        "  def _load_df(self):                                    \n",
        "       if self.train_test == 'train': \n",
        "            self.df = pd.read_csv(self.formated_train_path,sep=',')\n",
        "       else:\n",
        "            self.df = pd.read_csv(self.formated_test_path,sep=',')\n",
        "       self.index = np.random.randint(0,self.df.shape[0]-1,dtype=np.int32)  #getting the random state \n",
        "       self.loaded = True\n",
        "       for att in self.attack_map:\n",
        "         if att in self.df.columns:\n",
        "            if np.sum(self.df[att].values) > 1:\n",
        "               self.attack_names.append(att)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSLmFWDjJOww"
      },
      "source": [
        "def huber_loss(y_true,y_pred,clip_value=1):\n",
        "\n",
        "   assert clip_value > 0\n",
        "\n",
        "   x = y_true - y_pred\n",
        "   if np.isinf(clip_value):\n",
        "\n",
        "       return .5 * K.square(x)\n",
        "\n",
        "    \n",
        "   condition = K.abs(x) < clip_value\n",
        "   squared_loss = .5 * K.square(x)\n",
        "   linear_loss = clip_value * (K.abs(x) - .5 * clip_value)\n",
        "   if K.backend() == 'tensorflow':\n",
        "     import tensorflow as tf\n",
        "     if hasattr(tf,'select'):\n",
        "       return tf.select(condition,squared_loss,linear_loss)\n",
        "     else:\n",
        "       return tf.where(condition,squared_loss,linear_loss)\n",
        "   elif K.backend() == 'theano':\n",
        "     from theano import tensor as T\n",
        "     return T.switch(condition,squared_loss,linear_loss)\n",
        "   else:\n",
        "     raise RuntimeError('Unknown backend \"{}\".'.format(k.backend()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjKu8R7iK984"
      },
      "source": [
        "import keras.losses\n",
        "keras.losses.huber_loss = huber_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfAdSMFtLGzs"
      },
      "source": [
        "class QNetwork():\n",
        "\n",
        "  def __init__(self,obs_size,num_actions,hidden_size=100,hidden_layers = 1,learning_rate = .2):\n",
        "\n",
        "     self.obs_size = obs_size\n",
        "     self.num_actions = num_actions\n",
        "     self.model = Sequential()\n",
        "     # add input layer\n",
        "     self.model.add(Dense(hidden_size,input_shape=(obs_size, ),activation='relu')) \n",
        "     #add hidden layers\n",
        "     for layers in range(hidden_layers):\n",
        "       self.model.add(Dense(hidden_size,activation='relu'))\n",
        "      #add output layers.\n",
        "     self.model.add(Dense(num_actions))\n",
        "\n",
        "     optimizer = optimizers.Adam(0.00025)\n",
        "\n",
        "     self.model.compile(loss=huber_loss,optimizer = optimizer)\n",
        "\n",
        "     # predict action values\n",
        "  def predict(self,state,batch_size=1):\n",
        "\n",
        "      return self.model.predict(state,batch_size=batch_size)\n",
        "\n",
        "     #states: Target states\n",
        "      \n",
        "      #    q: Estimated values\n",
        "      #  Returns:\n",
        "       #   The calculated loss on the batch.\n",
        "  def update(self,states,q):\n",
        "\n",
        "    loss = self.model.train_on_batch(states,q)\n",
        "    return loss\n",
        "\n",
        "\n",
        "    \n",
        "  def copy_model(model):\n",
        "\n",
        "     model.save('tmp_model')\n",
        "     return keras.models.load_model('tmp_model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4aNrRlLJNcbd"
      },
      "source": [
        "class Policy:\n",
        "  def __init__(self,num_actions,estimator):\n",
        "    self.num_actions = num_actions\n",
        "    self.estimator = estimator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgUkayyENyAU"
      },
      "source": [
        "class Epsilon_greedy(Policy):\n",
        "\n",
        "  def __init__(self,estimator,num_actions,epsilon,min_epsilon,decay_rate,epoch_length):\n",
        "     Policy.__init__(self,num_actions,estimator)\n",
        "     self.name = \"Epsilon Greedy\"\n",
        "\n",
        "     if (epsilon is None or epsilon < 0 or epsilon > 1):\n",
        "        print(\"EpsilonGreedy : Invalid value of position\",flush = True)\n",
        "        sys.exit(0)\n",
        "     self.epsilon = epsilon\n",
        "\n",
        "     self.min_epsilon = min_epsilon\n",
        "\n",
        "     self.actions = list(range(num_actions))\n",
        "\n",
        "     self.step_counter = 0\n",
        "\n",
        "     self.epoch_length = epoch_length\n",
        "\n",
        "     self.decay_rate = decay_rate\n",
        "\n",
        "     if self.epsilon > 0.01:\n",
        "       self.epsilon_decay = True\n",
        "     else:\n",
        "       self.epsilon_decay = False\n",
        "\n",
        "  def get_actions(self,states):\n",
        "\n",
        "    if np.random.rand() <= self.epsilon:\n",
        "\n",
        "       actions = np.random.randint(0,self.num_actions,states.shape[0])\n",
        "    else:\n",
        "      self.Q = self.estimator.predict(states,states.shape[0])\n",
        "      actions = []\n",
        "      for row in range(self.Q.shape[0]):\n",
        "         best_actions = np.argwhere(self.Q[row] == np.amax(self.Q[row]))\n",
        "         actions.append(best_actions[np.random.choice(len(best_actions))].item())\n",
        "   \n",
        "    self.step_counter +=1\n",
        "\n",
        "    if self.epsilon_decay:\n",
        "      if self.step_counter % self.epoch_length == 0:\n",
        "         self.epsilon = max(self.min_epsilon,self.epsilon * self.decay_rate**self.step_counter)\n",
        "\n",
        "    return actions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWPvIoqpQdVR"
      },
      "source": [
        "class ReplayMemory(object):\n",
        "\n",
        "  def __init__(self,observation_size,max_size):\n",
        "\n",
        "    self.observation_size = observation_size\n",
        "    self.num_observed = 0\n",
        "    self.max_size = max_size\n",
        "    self.samples = {\n",
        "        \n",
        "         'obs' : np.zeros(self.max_size * 1 * self.observation_size,dtype=np.float32).reshape(self.max_size,self.observation_size),\n",
        "\n",
        "         'action' : np.zeros(self.max_size * 1 ,dtype=np.int16).reshape(self.max_size,1),\n",
        "         \n",
        "         'reward' : np.zeros(self.max_size * 1).reshape(self.max_size,1),\n",
        "\n",
        "         'terminal' : np.zeros(self.max_size *1 ,dtype=np.int16).reshape(self.max_size,1)\n",
        "    }\n",
        "    \n",
        "  def observe(self,state,action,reward,done):\n",
        "      index = self.num_observed % self.max_size\n",
        "      self.samples['obs'][index,:] = state\n",
        "      self.samples['action'][index,:]=action\n",
        "      self.samples['reward'][index,:]=reward\n",
        "      self.samples['terminal'][index,:]=done\n",
        "\n",
        "      self.num_observed +=1\n",
        "\n",
        "  def sample_minibatch(self,minibatch_size):\n",
        "      max_index = min(self.num_observed,self.max_size) - 1\n",
        "      sampled_indices = np.random.randint(max_index,size = minibatch_size)\n",
        "\n",
        "      s = np.asarray(self.samples['obs'][sampled_indices,:],dtype = np.float32)\n",
        "      s_next = np.asarray(self.samples['obs'][sampled_indices+1,:],dtype=np.float32)\n",
        "\n",
        "      a = self.samples['action'][sampled_indices].reshape(minibatch_size)\n",
        "\n",
        "      r = self.samples['reward'][sampled_indices].reshape((minibatch_size,1))\n",
        "\n",
        "      done = self.samples['terminal'][sampled_indices].reshape((minibatch_size,1))\n",
        "\n",
        "      return (s,a,r,s_next,done)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwwBcWFdWUbI"
      },
      "source": [
        "class Agent(object):\n",
        "\n",
        "  def __init__(self,actions,obs_size,policy=\"EpsilonGreedy\",**kwargs):\n",
        "    self.actions = actions\n",
        "    self.num_actions = len(actions)\n",
        "    self.obs_size = obs_size\n",
        "\n",
        "    self.epsilon = kwargs.get('epsilon',1)\n",
        "    self.min_epsilon = kwargs.get('min_epsilon',.1)\n",
        "    self.gamma = kwargs.get('gamma',.001)\n",
        "    self.minibatch_size = kwargs.get('minibatch_size',2)\n",
        "    self.epoch_length = kwargs.get('epoch_length',100)\n",
        "    self.decay_rate = kwargs.get('decay_rate',0.99)\n",
        "    self.ExpRep = kwargs.get('ExpRep',True)\n",
        "\n",
        "    if self.ExpRep:\n",
        "\n",
        "       self.memory = ReplayMemory(self.obs_size,kwargs.get('mem_size',10))\n",
        "    \n",
        "    self.ddqn_time = 100\n",
        "    self.ddqn_update = self.ddqn_time\n",
        "\n",
        "    self.model_network = QNetwork(self.obs_size,self.num_actions,\n",
        "                                  kwargs.get('hidden_size',100),\n",
        "                                  kwargs.get('hidden_layers',1),\n",
        "                                  kwargs.get('learning_rate',.2))\n",
        "    self.target_model_network = QNetwork(self.obs_size,self.num_actions,\n",
        "                                         kwargs.get('hidden_size',100),\n",
        "                                         kwargs.get('hidden_layers',1),\n",
        "                                         kwargs.get('learning_rate',.2))\n",
        "    self.target_model_network.model = QNetwork.copy_model(self.model_network.model)\n",
        "\n",
        "    if policy == 'EpsilonGreedy':\n",
        "      self.policy = Epsilon_greedy(self.model_network,len(actions),\n",
        "                                   self.epsilon,self.min_epsilon,\n",
        "                                   self.decay_rate,self.epoch_length)\n",
        "      \n",
        "  def learn(self,states,actions,next_states,rewards,done):\n",
        "\n",
        "    if self.ExpRep:\n",
        "        self.memory.observe(states,actions,rewards,done)\n",
        "    \n",
        "    else:\n",
        "        self.states = states\n",
        "        self.actions = actions\n",
        "        self.next_states = next_states\n",
        "        self.reward = rewards\n",
        "        self.done   = done\n",
        "\n",
        "  def update_model(self):\n",
        "\n",
        "     if self.ExpRep:\n",
        "           (states,actions,rewards,next_states,done) = self.memory.sample_minibatch(self.minibatch_size)\n",
        "\n",
        "     else:\n",
        "        \n",
        "         states = self.states\n",
        "         rewards = self.rewards\n",
        "         next_states = self.next_states\n",
        "         actions = self.actions\n",
        "         done = self.done\n",
        "     next_actions = []\n",
        "\n",
        "     Q_prime = self.target_model_network.predict(next_states,self.minibatch_size)\n",
        "\n",
        "\n",
        "     for row in range(Q_prime.shape[0]):\n",
        "\n",
        "         best_next_actions  = np.argwhere(Q_prime[row] == np.amax(Q_prime[row]))\n",
        "\n",
        "         next_actions.append(best_next_actions[np.random.choice(len(best_next_actions))].item())\n",
        "\n",
        "     sx = np.arange(len(next_actions))\n",
        "\n",
        "     Q = self.model_network.predict(states,self.minibatch_size)\n",
        "\n",
        "     targets = rewards.reshape(Q[sx,actions].shape) + \\\n",
        "                self.gamma * Q[sx,next_actions] * \\\n",
        "                (1-done.reshape(Q[sx,actions].shape))\n",
        "     Q[sx,actions] = targets\n",
        "\n",
        "     loss = self.model_network.model.train_on_batch(states,Q)\n",
        "\n",
        "     self.ddqn_update -=1\n",
        "\n",
        "     if self.ddqn_update == 0:\n",
        "\n",
        "        self.ddqn_update = self.ddqn_time\n",
        "\n",
        "        self.target_model_network.model.set_weights(self.model_network.model.get_weights())\n",
        "\n",
        "     return loss\n",
        "\n",
        "  def act(self,state,policy):\n",
        "\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CIj37YjFp2Oc"
      },
      "source": [
        "class DefenderAgent(Agent):\n",
        "  def __init__(self,actions,obs_size,policy=\"EpsilonGreedy\",**kwargs):\n",
        "     super().__init__(actions,obs_size,policy=\"EpsilonGreedy\",**kwargs)\n",
        "\n",
        "  def act(self,states):\n",
        "\n",
        "     actions = self.policy.get_actions(states)\n",
        "     return actions\n",
        "\n",
        "\n",
        "class AttackAgent(Agent):\n",
        "\n",
        "  def __init__(self,actions,obs_size,policy=\"EpsilonGreedy\",**kwargs):\n",
        "     super().__init__(actions,obs_size,policy=\"EpsilonGreedy\",**kwargs)\n",
        "\n",
        "  def act(self,states):\n",
        "\n",
        "     actions = self.policy.get_actions(states)\n",
        "     return actions\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWWb_tv6rOkV"
      },
      "source": [
        "class RLenv(data_cls):\n",
        "  def __init__(self,train_test,**kwargs):\n",
        "    data_cls.__init__(self,train_test,**kwargs)\n",
        "    data_cls._load_df(self)\n",
        "    self.data_shape = data_cls.get_shape(self)\n",
        "    self.batch_size = kwargs.get('batch_size',1)\n",
        "    self.iterations_episode = kwargs.get('iterations_episode',10)\n",
        "\n",
        "    if self.batch_size =='full':\n",
        "         self.batch_size = int(self.data_shape[0]/iterations_episode)\n",
        "\n",
        "  def _update_state(self):        \n",
        "        self.states,self.labels = data_cls.get_batch(self)\n",
        "        \n",
        "        # Update statistics\n",
        "        self.true_labels += np.sum(self.labels).values\n",
        "\n",
        "  def reset(self):\n",
        "        # Statistics\n",
        "    self.def_true_labels = np.zeros(len(self.attack_types),dtype=int)\n",
        "    self.def_estimated_labels = np.zeros(len(self.attack_types),dtype=int)\n",
        "    self.att_true_labels = np.zeros(len(self.attack_names),dtype=int)\n",
        "        \n",
        "    self.state_numb = 0\n",
        "    print(\"hello in reset state\")\n",
        "    data_cls._load_df(self) # Reload and random index\n",
        "    print(\"after load df\")\n",
        "    self.states,self.labels = data_cls.get_batch(self,self.batch_size)\n",
        "    print(\"states\") \n",
        "    self.total_reward = 0\n",
        "    self.steps_in_episode = 0\n",
        "    return self.states.values \n",
        "\n",
        "\n",
        "\n",
        "  def act(self,defender_actions,attack_actions):\n",
        "     self.att_reward = np.zeros(len(attack_actions))\n",
        "     self.def_reward = np.zeros(len(defender_actions))\n",
        "\n",
        "     attack = [self.attack_types.index(self.attack_map[self.attack_names[att]]) for att in attack_actions]\n",
        "\n",
        "     self.def_reward = (np.asarray(defender_actions)==np.asarray(attack))\n",
        "     self.att_reward = (np.asarray(defender_actions)!=np.asarray(attack))\n",
        "\n",
        "\n",
        "     self.def_estimated_labels += np.bincount(defender_actions,minlength=len(self.attack_types))\n",
        "\n",
        "     for act in attack_actions:\n",
        "        self.def_true_labels[self.attack_types.index(self.attack_map[self.attack_names[act]])] += 1\n",
        "\n",
        "     attack_actions = attacker_agent.act(self.states)\n",
        "\n",
        "     self.states = env.get_states(attack_actions)\n",
        "\n",
        "     self.done = np.zeros(len(attack_actions),dtype=bool)\n",
        "\n",
        "\n",
        "     return self.states,self.def_reward,self.att_reward,attack_actions,self.done\n",
        "\n",
        "  def get_states(self,attacker_actions):\n",
        "    first = True\n",
        "    for attack in attacker_actions:\n",
        "      if first:\n",
        "        minibatch = (self.df[self.df[self.attack_names[attack]]== 1].sample(1))\n",
        "        first = False\n",
        "      else:\n",
        "        minibatch = minibatch.append(self.df[self.df[self.attack_names[attack]]==1].sample(1))\n",
        "    \n",
        "    self.labels = minibatch[self.attack_names]\n",
        "    minibatch.drop(self.all_attack_names,axis=1,inplace=True)\n",
        "    self.states = minibatch\n",
        "\n",
        "    return self.states\n",
        "\n",
        "\n",
        "     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y28Y8PdnxIUJ"
      },
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "  kdd_20_path = '/content/datasets/datasets/NSL/KDDTrain+_20Percent.txt'\n",
        "  kdd_train = '/content/datasets/datasets/NSL/KDDTrain+.txt'\n",
        "  kdd_test = '/content/datasets/datasets/NSL/KDDTest+.txt'\n",
        "\n",
        "  formated_train_path = \"/content/datasets/datasets/formated/formated_train_adv.data.txt\"\n",
        "  formated_test_path = \"/content/datasets/datasets/formated/formated_test_adv.data.txt\"\n",
        "   \n",
        "  batch_size = 1\n",
        "\n",
        "  minibatch_size = 100\n",
        "\n",
        "  ExpRep = True\n",
        "\n",
        "  iterations_episode = 100\n",
        "\n",
        "\n",
        "  env = RLenv('train',train_path=kdd_train,test_path=kdd_test,\n",
        "              formated_train_path = formated_train_path,\n",
        "              formated_test_path = formated_test_path,batch_size = batch_size,\n",
        "              iterations_episode = iterations_episode)\n",
        "  obs_size = env.data_shape[1]-len(env.all_attack_names)\n",
        "\n",
        "  num_episodes = 100\n",
        "\n",
        "\n",
        "  #Definition for the defensor agent\n",
        "\n",
        "  defender_valid_actions = list(range(len(env.attack_types)))\n",
        "\n",
        "  defender_num_actions = len(defender_valid_actions)\n",
        "\n",
        "\n",
        "  def_epsilon = 1  #exploration\n",
        "  min_epsilon = 0.01 #min value for exploration\n",
        "  def_gamma = 0.001\n",
        "  def_decay_rate = 0.99\n",
        "\n",
        "  def_hidden_size = 100\n",
        "  def_hidden_layers = 5\n",
        "\n",
        "  def_learning_rate = .2\n",
        "\n",
        "  defender_agent = DefenderAgent(defender_valid_actions,obs_size,\"EpsilonGreedy\",\n",
        "                          epoch_length = iterations_episode,\n",
        "                          epsilon = def_epsilon,\n",
        "                          min_epsilon = min_epsilon,\n",
        "                          decay_rate = def_decay_rate,\n",
        "                          gamma = def_gamma,\n",
        "                          hidden_size=def_hidden_size,\n",
        "                          hidden_layers=def_hidden_layers,\n",
        "                          minibatch_size = minibatch_size,\n",
        "                          mem_size = 1000,\n",
        "                          learning_rate=def_learning_rate,\n",
        "                          ExpRep=ExpRep)\n",
        "  \n",
        "  #definitation of Attacker agent\n",
        "\n",
        "  attack_valid_actions = list(range(len(env.attack_names)))\n",
        "  attack_num_actions = len(attack_valid_actions)\n",
        "\n",
        "  att_epsilon = 1\n",
        "  min_epsilon = 0.8\n",
        "\n",
        "  att_gamma = 0.001\n",
        "\n",
        "  att_decay_rate = 0.99\n",
        "\n",
        "  att_hidden_layers = 3\n",
        "  att_hidden_size = 100\n",
        "  att_learning_rate = 0.2\n",
        "\n",
        "  \n",
        "  attacker_agent = AttackAgent(attack_valid_actions,obs_size,\"EpsilonGreedy\",\n",
        "                          epoch_length = iterations_episode,\n",
        "                          epsilon = att_epsilon,\n",
        "                          min_epsilon = min_epsilon,\n",
        "                          decay_rate = att_decay_rate,\n",
        "                          gamma = att_gamma,\n",
        "                          hidden_size=att_hidden_size,\n",
        "                          hidden_layers=att_hidden_layers,\n",
        "                          minibatch_size = minibatch_size,\n",
        "                          mem_size = 1000,\n",
        "                          learning_rate=att_learning_rate,\n",
        "                          ExpRep=ExpRep)\n",
        "  \n",
        "  att_reward_chain = []\n",
        "  def_reward_chain = []\n",
        "  att_loss_chain = []\n",
        "  def_loss_chain = []\n",
        "  def_total_reward_chain = []\n",
        "  att_total_reward_chain = []\n",
        "\n",
        "  print(\"-------------------------------------------------------------------------------\")\n",
        "  print(\"Total epoch: {} | Iterations in epoch: {}\"\n",
        "          \"| Minibatch from mem size: {} | Total Samples: {}|\".format(num_episodes,\n",
        "                         iterations_episode,minibatch_size,\n",
        "                         num_episodes*iterations_episode))\n",
        "  print(\"-------------------------------------------------------------------------------\")\n",
        "  print(\"Dataset shape: {}\".format(env.data_shape))\n",
        "  print(\"-------------------------------------------------------------------------------\")\n",
        "  print(\"Attacker parameters: Num_actions={} | gamma={} |\" \n",
        "          \" epsilon={} | ANN hidden size={} | \"\n",
        "          \"ANN hidden layers={}|\".format(attack_num_actions,\n",
        "                             att_gamma,att_epsilon, att_hidden_size,\n",
        "                             att_hidden_layers))\n",
        "  print(\"-------------------------------------------------------------------------------\")\n",
        "  print(\"Defense parameters: Num_actions={} | gamma={} | \"\n",
        "          \"epsilon={} | ANN hidden size={} |\"\n",
        "          \" ANN hidden layers={}|\".format(defender_num_actions,\n",
        "                              def_gamma,def_epsilon,def_hidden_size,\n",
        "                              def_hidden_layers))\n",
        "  print(\"-------------------------------------------------------------------------------\")\n",
        "\n",
        "    # Main loop\n",
        "  for epoch in range(num_episodes):\n",
        "      start_time = time.time()\n",
        "      att_loss = 0.\n",
        "      def_loss = 0.\n",
        "      def_total_reward_by_episode = 0\n",
        "      att_total_reward_by_episode = 0\n",
        "        # Reset enviromet, actualize the data batch with random state/attacks\n",
        "      states = env.reset()\n",
        "        \n",
        "        # Get actions for actual states following the policy\n",
        "      attack_actions = attacker_agent.act(states)\n",
        "      states = env.get_states(attack_actions)    \n",
        "\n",
        "        \n",
        "        \n",
        "        \n",
        "        \n",
        "      done = False\n",
        "       \n",
        "\n",
        "        # Iteration in one episode\n",
        "      for i_iteration in range(iterations_episode):\n",
        "            \n",
        "            \n",
        "            # apply actions, get rewards and new state\n",
        "          act_time = time.time()  \n",
        "          defender_actions = defender_agent.act(states)\n",
        "            #Enviroment actuation for this actions\n",
        "          next_states,def_reward, att_reward,next_attack_actions, done = env.act(defender_actions,attack_actions)\n",
        "            # If the epoch*batch_size*iterations_episode is largest than the df\n",
        "\n",
        "            \n",
        "          attacker_agent.learn(states,attack_actions,next_states,att_reward,done)\n",
        "          defender_agent.learn(states,defender_actions,next_states,def_reward,done)\n",
        "            \n",
        "          act_end_time = time.time()\n",
        "            \n",
        "            # Train network, update loss after at least minibatch_learns\n",
        "          if ExpRep and epoch*iterations_episode + i_iteration >= minibatch_size:\n",
        "              def_loss += defender_agent.update_model()\n",
        "              att_loss += attacker_agent.update_model()\n",
        "          elif not ExpRep:\n",
        "              def_loss += defender_agent.update_model()\n",
        "              att_loss += attacker_agent.update_model()\n",
        "                \n",
        "\n",
        "          update_end_time = time.time()\n",
        "\n",
        "            # Update the state\n",
        "          states = next_states\n",
        "          attack_actions = next_attack_actions\n",
        "            \n",
        "            \n",
        "            # Update statistics\n",
        "          def_total_reward_by_episode += np.sum(def_reward,dtype=np.int32)\n",
        "          att_total_reward_by_episode += np.sum(att_reward,dtype=np.int32)\n",
        "        \n",
        "\n",
        "        # Update user view\n",
        "      def_reward_chain.append(def_total_reward_by_episode) \n",
        "      att_reward_chain.append(att_total_reward_by_episode) \n",
        "      def_loss_chain.append(def_loss)\n",
        "      att_loss_chain.append(att_loss) \n",
        "\n",
        "        \n",
        "      end_time = time.time()\n",
        "      print(\"\\r\\n|Epoch {:03d}/{:03d}| time: {:2.2f}|\\r\\n\"\n",
        "                \"|Def Loss {:4.4f} | Def Reward in ep {:03d}|\\r\\n\"\n",
        "                \"|Att Loss {:4.4f} | Att Reward in ep {:03d}|\"\n",
        "                .format(epoch, num_episodes,(end_time-start_time), \n",
        "                def_loss, def_total_reward_by_episode,\n",
        "                att_loss, att_total_reward_by_episode))\n",
        "        \n",
        "        \n",
        "      print(\"|Def Estimated: {}| Att Labels: {}\".format(env.def_estimated_labels,\n",
        "              env.def_true_labels))\n",
        "        \n",
        "    # Save trained model weights and architecture, used in test\n",
        "  defender_agent.model_network.model.save_weights(\"/content/datasets/datasets/results/defender_agent_model.h5\", overwrite=True)\n",
        "  with open(\"/content/datasets/datasets/results/defender_agent_model.json\", \"w\") as outfile:\n",
        "    json.dump(defender_agent.model_network.model.to_json(), outfile)\n",
        "        \n",
        "        \n",
        "    # Plot training results\n",
        "  plt.figure(1)\n",
        "  plt.subplot(211)\n",
        "  plt.plot(np.arange(len(def_reward_chain)),def_reward_chain,label='Defense')\n",
        "  plt.plot(np.arange(len(att_reward_chain)),att_reward_chain,label='Attack')\n",
        "  plt.title('Total reward by episode')\n",
        "  plt.xlabel('n Episode')\n",
        "  plt.ylabel('Total reward')\n",
        "  plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
        "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
        "    \n",
        "  plt.subplot(212)\n",
        "  plt.plot(np.arange(len(def_loss_chain)),def_loss_chain,label='Defense')\n",
        "  plt.plot(np.arange(len(att_loss_chain)),att_loss_chain,label='Attack')\n",
        "  plt.title('Loss by episode')\n",
        "  plt.xlabel('n Episode')\n",
        "  plt.ylabel('loss')\n",
        "  plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
        "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
        "  plt.tight_layout()\n",
        "    #plt.show()\n",
        "  plt.savefig('/content/datasets/datasets/results/train_adv.eps', format='eps', dpi=1000)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-_KjOGL5tM3"
      },
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import model_from_json\n",
        "#from adversarialAD import RLenv\n",
        "import matplotlib.pyplot as plt\n",
        "#from adversarialAD import huber_loss\n",
        "\n",
        "import itertools\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.metrics import  confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 10\n",
        "formated_test_path = \"/content/datasets/datasets/formated/formated_test_adv.data.txt\"\n",
        "\n",
        "with open(\"/content/datasets/datasets/results/defender_agent_model.json\", \"r\") as jfile:\n",
        "    model = model_from_json(json.load(jfile))\n",
        "model.load_weights(\"/content/datasets/datasets/results/defender_agent_model.h5\")\n",
        "model.compile(loss=huber_loss,optimizer='sgd')\n",
        "\n",
        "# Define environment, game, make sure the batch_size is the same in train\n",
        "env = RLenv('test',formated_test_path = formated_test_path)\n",
        "\n",
        "\n",
        "total_reward = 0    \n",
        "\n",
        "\n",
        "true_labels = np.zeros(len(env.attack_types),dtype=int)\n",
        "estimated_labels = np.zeros(len(env.attack_types),dtype=int)\n",
        "estimated_correct_labels = np.zeros(len(env.attack_types),dtype=int)\n",
        "\n",
        "#states , labels = env.get_sequential_batch(test_path,batch_size = env.batch_size)\n",
        "states , labels = env.get_full()\n",
        "q = model.predict(states)\n",
        "actions = np.argmax(q,axis=1)        \n",
        "\n",
        "maped=[]\n",
        "for indx,label in labels.iterrows():\n",
        "    maped.append(env.attack_types.index(env.attack_map[label.idxmax()]))\n",
        "\n",
        "labels,counts = np.unique(maped,return_counts=True)\n",
        "true_labels[labels] += counts\n",
        "\n",
        "\n",
        "\n",
        "for indx,a in enumerate(actions):\n",
        "    estimated_labels[a] +=1              \n",
        "    if a == maped[indx]:\n",
        "        total_reward += 1\n",
        "        estimated_correct_labels[a] += 1\n",
        "\n",
        "\n",
        "action_dummies = pd.get_dummies(actions)\n",
        "posible_actions = np.arange(len(env.attack_types))\n",
        "for non_existing_action in posible_actions:\n",
        "    if non_existing_action not in action_dummies.columns:\n",
        "        action_dummies[non_existing_action] = np.uint8(0)\n",
        "labels_dummies = pd.get_dummies(maped)\n",
        "\n",
        "normal_f1_score = f1_score(labels_dummies[0].values,action_dummies[0].values)\n",
        "dos_f1_score = f1_score(labels_dummies[1].values,action_dummies[1].values)\n",
        "probe_f1_score = f1_score(labels_dummies[2].values,action_dummies[2].values)\n",
        "r2l_f1_score = f1_score(labels_dummies[3].values,action_dummies[3].values)\n",
        "u2r_f1_score = f1_score(labels_dummies[4].values,action_dummies[4].values)\n",
        "    \n",
        "\n",
        "Accuracy = [normal_f1_score,dos_f1_score,probe_f1_score,r2l_f1_score,u2r_f1_score]\n",
        "Mismatch = estimated_labels - true_labels\n",
        "\n",
        "acc = float(100*total_reward/len(states))\n",
        "print('\\r\\nTotal reward: {} | Number of samples: {} | Accuracy = {:.2f}%'.format(total_reward,\n",
        "      len(states),acc))\n",
        "outputs_df = pd.DataFrame(index = env.attack_types,columns = [\"Estimated\",\"Correct\",\"Total\",\"F1_score\"])\n",
        "for indx,att in enumerate(env.attack_types):\n",
        "   outputs_df.iloc[indx].Estimated = estimated_labels[indx]\n",
        "   outputs_df.iloc[indx].Correct = estimated_correct_labels[indx]\n",
        "   outputs_df.iloc[indx].Total = true_labels[indx]\n",
        "   outputs_df.iloc[indx].F1_score = Accuracy[indx]*100\n",
        "   outputs_df.iloc[indx].Mismatch = abs(Mismatch[indx])\n",
        "\n",
        "##############\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "    #%%\n",
        "\n",
        "print(outputs_df)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "width = 0.35\n",
        "pos = np.arange(len(true_labels))\n",
        "p1 = plt.bar(pos, estimated_correct_labels,width,color='g')\n",
        "p1 = plt.bar(pos+width,\n",
        "             (np.abs(estimated_correct_labels-true_labels)),width,\n",
        "             color='r')\n",
        "p2 = plt.bar(pos+width,np.abs(estimated_labels-estimated_correct_labels),width,\n",
        "             bottom=(np.abs(estimated_correct_labels-true_labels)),\n",
        "             color='b')\n",
        "\n",
        "\n",
        "ax.set_xticks(pos+width/2)\n",
        "ax.set_xticklabels(env.attack_types,rotation='vertical')\n",
        "#ax.set_yscale('log')\n",
        "\n",
        "#ax.set_ylim([0, 100])\n",
        "ax.set_title('Test set scores, Acc = {:.2f}'.format(acc))\n",
        "plt.legend(('Correct estimated','False negative','False positive'))\n",
        "plt.tight_layout()\n",
        "#plt.show()\n",
        "plt.savefig('/content/datasets/datasets/test_adv_imp.svg', format='svg', dpi=1000)\n",
        "\n",
        "\n",
        "#%% Agregated precision\n",
        "\n",
        "aggregated_data_test = np.array(maped)\n",
        "\n",
        "print('Performance measures on Test data')\n",
        "print('Accuracy =  {:.4f}'.format(accuracy_score( aggregated_data_test,actions)))\n",
        "print('F1 =  {:.4f}'.format(f1_score(aggregated_data_test,actions, average='weighted')))\n",
        "print('Precision_score =  {:.4f}'.format(precision_score(aggregated_data_test,actions, average='weighted')))\n",
        "print('recall_score =  {:.4f}'.format(recall_score(aggregated_data_test,actions, average='weighted')))\n",
        "\n",
        "cnf_matrix = confusion_matrix(aggregated_data_test,actions)\n",
        "np.set_printoptions(precision=2)\n",
        "plt.figure()\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cnf_matrix, classes=env.attack_types, normalize=True,\n",
        "                      title='Normalized confusion matrix')\n",
        "plt.savefig('/content/datasets/datasets/confusion_matrix_adversarial.svg', format='svg', dpi=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhUcEi_fYitk",
        "outputId": "ea4ca0b3-fad3-4a3a-e1b5-7f84a0638bb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "source": [
        "df2 = pd.read_csv('/content/datasets/datasets/formated/formated_train_adv.data.txt')\n",
        "df2.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>duration</th>\n",
              "      <th>src_bytes</th>\n",
              "      <th>dst_bytes</th>\n",
              "      <th>land_f</th>\n",
              "      <th>wrong_fragment</th>\n",
              "      <th>urgent</th>\n",
              "      <th>hot</th>\n",
              "      <th>num_failed_logins</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>num_compromised</th>\n",
              "      <th>root_shell</th>\n",
              "      <th>su_attempted</th>\n",
              "      <th>num_root</th>\n",
              "      <th>num_file_creations</th>\n",
              "      <th>num_shells</th>\n",
              "      <th>num_access_files</th>\n",
              "      <th>num_outbound_cmds</th>\n",
              "      <th>is_host_login</th>\n",
              "      <th>is_guest_login</th>\n",
              "      <th>count</th>\n",
              "      <th>srv_count</th>\n",
              "      <th>serror_rate</th>\n",
              "      <th>srv_serror_rate</th>\n",
              "      <th>rerror_rate</th>\n",
              "      <th>srv_rerror_rate</th>\n",
              "      <th>same_srv_rate</th>\n",
              "      <th>diff_srv_rate</th>\n",
              "      <th>srv_diff_host_rate</th>\n",
              "      <th>dst_host_count</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_diff_srv_rate</th>\n",
              "      <th>dst_host_same_src_port_rate</th>\n",
              "      <th>dst_host_srv_diff_host_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>dst_host_rerror_rate</th>\n",
              "      <th>dst_host_srv_rerror_rate</th>\n",
              "      <th>icmp</th>\n",
              "      <th>tcp</th>\n",
              "      <th>...</th>\n",
              "      <th>apache2</th>\n",
              "      <th>back</th>\n",
              "      <th>buffer_overflow</th>\n",
              "      <th>ftp_write</th>\n",
              "      <th>guess_passwd</th>\n",
              "      <th>httptunnel</th>\n",
              "      <th>imap</th>\n",
              "      <th>ipsweep</th>\n",
              "      <th>land</th>\n",
              "      <th>loadmodule</th>\n",
              "      <th>mailbomb</th>\n",
              "      <th>mscan</th>\n",
              "      <th>multihop</th>\n",
              "      <th>named</th>\n",
              "      <th>neptune</th>\n",
              "      <th>nmap</th>\n",
              "      <th>normal</th>\n",
              "      <th>perl</th>\n",
              "      <th>phf</th>\n",
              "      <th>pod</th>\n",
              "      <th>portsweep</th>\n",
              "      <th>processtable</th>\n",
              "      <th>ps</th>\n",
              "      <th>rootkit</th>\n",
              "      <th>saint</th>\n",
              "      <th>satan</th>\n",
              "      <th>sendmail</th>\n",
              "      <th>smurf</th>\n",
              "      <th>snmpgetattack</th>\n",
              "      <th>snmpguess</th>\n",
              "      <th>spy</th>\n",
              "      <th>sqlattack</th>\n",
              "      <th>teardrop</th>\n",
              "      <th>udpstorm</th>\n",
              "      <th>warezclient</th>\n",
              "      <th>warezmaster</th>\n",
              "      <th>worm</th>\n",
              "      <th>xlock</th>\n",
              "      <th>xsnoop</th>\n",
              "      <th>xterm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.115997e-07</td>\n",
              "      <td>1.007834e-05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001957</td>\n",
              "      <td>0.001957</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.062745</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.103718</td>\n",
              "      <td>0.033268</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.258824</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.115997e-07</td>\n",
              "      <td>1.885586e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.035225</td>\n",
              "      <td>0.037182</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.207843</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.456560e-07</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001957</td>\n",
              "      <td>0.001957</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.090196</td>\n",
              "      <td>0.278431</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.91</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000035</td>\n",
              "      <td>3.374001e-06</td>\n",
              "      <td>2.534472e-07</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.001957</td>\n",
              "      <td>0.001957</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.411765</td>\n",
              "      <td>0.670588</td>\n",
              "      <td>0.87</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.952277e-05</td>\n",
              "      <td>6.346868e-06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019802</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000134</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005871</td>\n",
              "      <td>0.005871</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.592157</td>\n",
              "      <td>0.592157</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.536298e-08</td>\n",
              "      <td>7.252255e-08</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.005871</td>\n",
              "      <td>0.005871</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.592157</td>\n",
              "      <td>0.819608</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.90</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.557730</td>\n",
              "      <td>0.039139</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.137255</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.952277e-05</td>\n",
              "      <td>6.346868e-06</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.019802</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000134</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007828</td>\n",
              "      <td>0.007828</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.184314</td>\n",
              "      <td>0.184314</td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.532290</td>\n",
              "      <td>0.029354</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.058824</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10 rows  162 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   duration     src_bytes     dst_bytes  land_f  ...  worm  xlock  xsnoop  xterm\n",
              "0  0.000000  2.115997e-07  1.007834e-05     0.0  ...     0      0       0      0\n",
              "1  0.000000  0.000000e+00  0.000000e+00     0.0  ...     0      0       0      0\n",
              "2  0.000000  2.115997e-07  1.885586e-07     0.0  ...     0      0       0      0\n",
              "3  0.000000  1.456560e-07  0.000000e+00     0.0  ...     0      0       0      0\n",
              "4  0.000035  3.374001e-06  2.534472e-07     0.0  ...     0      0       0      0\n",
              "5  0.000000  3.952277e-05  6.346868e-06     0.0  ...     0      0       0      0\n",
              "6  0.000000  2.536298e-08  7.252255e-08     0.0  ...     0      0       0      0\n",
              "7  0.000000  0.000000e+00  0.000000e+00     0.0  ...     0      0       0      0\n",
              "8  0.000000  3.952277e-05  6.346868e-06     0.0  ...     0      0       0      0\n",
              "9  0.000000  0.000000e+00  0.000000e+00     0.0  ...     0      0       0      0\n",
              "\n",
              "[10 rows x 162 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    }
  ]
}